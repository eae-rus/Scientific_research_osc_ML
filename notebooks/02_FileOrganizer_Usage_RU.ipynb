{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Демонстрация использования класса `FileOrganizer`\n",
    "\n",
    "Этот ноутбук показывает, как использовать класс `FileOrganizer` из `filesystem.organizer` для выполнения различных операций по организации файлов осциллограмм:\n",
    "- Обновление времени модификации файлов.\n",
    "- Извлечение информации о частоте сети и дискретизации из `.cfg` файлов.\n",
    "- Группировка файлов осциллограмм по этим частотам.\n",
    "- Создание инвентарного CSV-файла с хеш-суммами `.dat` файлов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно**: Этот ноутбук использует образцы файлов из директории `tests/sample_data/`. Для демонстрации файлы копируются во временную рабочую директорию (`temp_organizer_notebook_data/source_oscillograms_for_grouping`). Убедитесь, что тестовые данные были сгенерированы запуском скрипта `tests/test_data_setup.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import pandas as pd # For displaying CSV content\n",
    "import numpy as np # For any sample data generation if needed, though ideally not\n",
    "import sys\n",
    "\n",
    "# --- Пути к данным для тестирования ---\n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from filesystem.organizer import FileOrganizer # Import after sys.path modification\n",
    "\n",
    "base_sample_data_dir = os.path.join(module_path, \"tests\", \"sample_data\")\n",
    "comtrade_samples_path = os.path.join(base_sample_data_dir, \"comtrade_files\")\n",
    "\n",
    "# --- Создание временной рабочей директории для этого ноутбука ---\n",
    "notebook_base_temp_dir = \"temp_organizer_notebook_data\"\n",
    "# This will be the main directory passed to FileOrganizer methods like group_files or generate_inventory\n",
    "notebook_source_dir = os.path.join(notebook_base_temp_dir, \"source_oscillograms_for_grouping\") \n",
    "    \n",
    "if os.path.exists(notebook_base_temp_dir):\n",
    "    shutil.rmtree(notebook_base_temp_dir)\n",
    "os.makedirs(notebook_source_dir) # Create the source dir where files will be copied/grouped\n",
    "\n",
    "# --- Копирование необходимых файлов для демонстрации ---\n",
    "# Файлы из tests/sample_data/comtrade_files/\n",
    "# 1. sample_A.cfg/dat (from valid_cfg_dat_1_subdir) -> 50Hz, 1000sps\n",
    "shutil.copy(os.path.join(comtrade_samples_path, \"valid_cfg_dat_1_subdir\", \"sample_A.cfg\"), notebook_source_dir)\n",
    "shutil.copy(os.path.join(comtrade_samples_path, \"valid_cfg_dat_1_subdir\", \"sample_A.dat\"), notebook_source_dir)\n",
    "\n",
    "# 2. cp1251_encoded.cfg/dat (from encoding_tests) -> Assuming 50Hz, 1500sps for simplicity or specific values if set up\n",
    "#    (Ensure test_data_setup.py creates cp1251_encoded.cfg with these frequencies)\n",
    "shutil.copy(os.path.join(comtrade_samples_path, \"encoding_tests\", \"cp1251_encoded.cfg\"), notebook_source_dir)\n",
    "shutil.copy(os.path.join(comtrade_samples_path, \"encoding_tests\", \"cp1251_encoded.dat\"), notebook_source_dir)\n",
    "    \n",
    "# 3. malformed_cfg_1.cfg (from malformed_cfg_files)\n",
    "shutil.copy(os.path.join(comtrade_samples_path, \"malformed_cfg_files\", \"malformed_cfg_1.cfg\"), notebook_source_dir)\n",
    "# (No DAT needed for malformed CFG if only frequency extraction is tested on it)\n",
    "\n",
    "# 4. A CFG file without DAT for testing grouping robustness\n",
    "with open(os.path.join(notebook_source_dir, \"cfg_no_dat.cfg\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    # Simplified CFG content\n",
    "    f.write(\"DummyStation,NoDatDevice,1999\\n1,1A,0D\\n1,NoDatSig,,V,1,0,0,0,100,1,1,P\\n50.0\\n1\\n1000,10\\n01/01/2023,00:00:00.000\\n01/01/2023,00:00:01.000\\nASCII\\n1\\n\")\n",
    "        \n",
    "# 5. A file with different frequencies for grouping, e.g., 60Hz, 2000sps\n",
    "#    (Ensure test_data_setup.py creates a file like 'sample_B_60_2k.cfg/dat')\n",
    "sample_B_path = os.path.join(comtrade_samples_path, \"for_grouping_B\") # Assume a subdir for_grouping_B\n",
    "if os.path.exists(os.path.join(sample_B_path, \"sample_B_60_2k.cfg\")):\n",
    "    shutil.copy(os.path.join(sample_B_path, \"sample_B_60_2k.cfg\"), notebook_source_dir)\n",
    "    shutil.copy(os.path.join(sample_B_path, \"sample_B_60_2k.dat\"), notebook_source_dir)\n",
    "    print(f\"Copied sample_B_60_2k from {sample_B_path}\")\n",
    "else:\n",
    "    print(f\"Warning: sample_B_60_2k.cfg not found in {sample_B_path}. Grouping test might be less effective.\")\n",
    "\n",
    "print(f\"Демонстрационная директория для FileOrganizer: {notebook_source_dir}\")\n",
    "print(\"Содержимое:\")\n",
    "for item in os.listdir(notebook_source_dir): print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Инициализация `FileOrganizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organizer = FileOrganizer()\n",
    "# Для более подробного вывода можно передать is_print_message=True в методы ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обновление времени модификации файлов (`update_modification_times`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Время модификации до обновления:\")\n",
    "for item in os.listdir(notebook_source_dir):\n",
    "    stat_info = os.stat(os.path.join(notebook_source_dir, item))\n",
    "    print(f\"- {item}: {datetime.datetime.fromtimestamp(stat_info.st_mtime)}\")\n",
    "\n",
    "print(\"\\nОбновляем время модификации...\")\n",
    "# Установим конкретное время для наглядности\n",
    "custom_datetime = datetime.datetime(2020, 1, 1, 12, 0, 0)\n",
    "organizer.update_modification_times(notebook_source_dir, new_mod_time=custom_datetime)\n",
    "\n",
    "print(\"\\nВремя модификации после обновления:\")\n",
    "for item in os.listdir(notebook_source_dir):\n",
    "    stat_info = os.stat(os.path.join(notebook_source_dir, item))\n",
    "    print(f\"- {item}: {datetime.datetime.fromtimestamp(stat_info.st_mtime)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Извлечение частот из `.cfg` файла (`extract_frequencies_from_cfg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path_sample_A = os.path.join(notebook_source_dir, \"sample_A.cfg\")\n",
    "cfg_path_malformed = os.path.join(notebook_source_dir, \"malformed_cfg_1.cfg\")\n",
    "cfg_path_cp1251 = os.path.join(notebook_source_dir, \"cp1251_encoded.cfg\")\n",
    "\n",
    "print(f\"Извлечение частот из {os.path.basename(cfg_path_sample_A)}:\")\n",
    "freq_net1, freq_rate1 = organizer.extract_frequencies_from_cfg(cfg_path_sample_A, encoding='utf-8', threshold=0.1)\n",
    "print(f\"  Частота сети: {freq_net1} Гц, Частота дискретизации: {freq_rate1} Гц (Ожидается: 50, 1000)\")\n",
    "\n",
    "print(f\"\\nИзвлечение частот из {os.path.basename(cfg_path_malformed)} (ожидаются ошибки/None):\")\n",
    "freq_net_mal, freq_rate_mal = organizer.extract_frequencies_from_cfg(cfg_path_malformed, encoding='utf-8')\n",
    "print(f\"  Частота сети: {freq_net_mal}, Частота дискретизации: {freq_rate_mal}\")\n",
    "\n",
    "print(f\"\\nИзвлечение частот из {os.path.basename(cfg_path_cp1251)} (кодировка cp1251):\")\n",
    "freq_net_cp, freq_rate_cp = organizer.extract_frequencies_from_cfg(cfg_path_cp1251, encoding='cp1251')\n",
    "print(f\"  Частота сети: {freq_net_cp} Гц, Частота дискретизации: {freq_rate_cp} Гц (Ожидается: 50, 1500)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Группировка файлов по частотам (`group_files_by_frequency_and_rate`)\n",
    "\n",
    "Этот метод сканирует указанную директорию, извлекает частоты из `.cfg` файлов и перемещает соответствующие пары `.cfg` и `.dat` в поддиректории вида `f_network = X and f_rate = Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nЗапуск группировки файлов в директории: {notebook_source_dir}\")\n",
    "organizer.group_files_by_frequency_and_rate(notebook_source_dir, is_print_message=True, show_progress=True)\n",
    "\n",
    "print(\"\\nСтруктура директории после группировки:\")\n",
    "for root, dirs, files in os.walk(notebook_source_dir):\n",
    "    level = root.replace(notebook_source_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * (level)\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    sub_indent = ' ' * 4 * (level + 1)\n",
    "    for f_name in files:\n",
    "        print(f\"{sub_indent}{f_name}\")\n",
    "\n",
    "print(\"\\nПроверка оставшихся файлов в корневой директории источника (должны остаться только те, что не удалось сгруппировать):\")\n",
    "for item in os.listdir(notebook_source_dir):\n",
    "    if os.path.isfile(os.path.join(notebook_source_dir, item)):\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Создание инвентарного CSV с хешами `.dat` файлов (`generate_dat_hash_inventory`)\n",
    "\n",
    "Этот метод работает с директорией, уже структурированной по частотам (как после `group_files_by_frequency_and_rate`). Он создает CSV-файл с информацией о каждом `.dat` файле, включая его хеш-сумму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_csv_path = os.path.join(notebook_base_temp_dir, \"dat_inventory.csv\")\n",
    "\n",
    "print(f\"\\nСоздание инвентарного CSV для директории: {notebook_source_dir}\")\n",
    "organizer.generate_dat_hash_inventory(notebook_source_dir, inventory_csv_path, show_progress=True)\n",
    "\n",
    "if os.path.exists(inventory_csv_path):\n",
    "    print(f\"\\nСодержимое инвентарного CSV ({inventory_csv_path}):\")\n",
    "    try:\n",
    "        inventory_df = pd.read_csv(inventory_csv_path)\n",
    "        if pd.__version__ > '1.0.0':\n",
    "            try:\n",
    "                from IPython.display import display\n",
    "                display(inventory_df)\n",
    "            except ImportError:\n",
    "                print(inventory_df)\n",
    "        else:\n",
    "            print(inventory_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка чтения CSV: {e}\")\n",
    "else:\n",
    "    print(f\"Инвентарный CSV не был создан (возможно, не было подходящих поддиректорий или .dat файлов).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка временной директории\n",
    "try:\n",
    "    if os.path.exists(notebook_base_temp_dir):\n",
    "        shutil.rmtree(notebook_base_temp_dir)\n",
    "        print(f\"\\nВременная директория {notebook_base_temp_dir} удалена.\")\n",
    "    else:\n",
    "        print(f\"\\nВременная директория {notebook_base_temp_dir} не найдена для удаления.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при удалении временной директории {notebook_base_temp_dir}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
