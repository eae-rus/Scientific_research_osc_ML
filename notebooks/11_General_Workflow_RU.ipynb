{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример общего рабочего процесса обработки осциллограмм\n",
    "\n",
    "Этот ноутбук демонстрирует возможную последовательность шагов при обработке коллекции осциллограмм с использованием ранее созданных модульных классов. Каждый этап может быть адаптирован, пропущен или выполнен независимо в соответствии с конкретными задачами.\n",
    "\n",
    "**Этапы рабочего процесса:**\n",
    "1.  **Обнаружение и сбор осциллограмм**: Используем `OscillogramFinder` для поиска и копирования файлов нужных типов из исходной директории (включая архивы) в рабочую директорию.\n",
    "2.  **Анонимизация**: Применяем `DataAnonymizer` для удаления конфиденциальной информации и переименования файлов по хеш-сумме.\n",
    "3.  **Каталогизация имен сигналов**: Используем `SignalNameManager` для создания каталога всех имен сигналов. (Опционально: их последующее переименование).\n",
    "4.  **Фильтрация по активности**: Применяем `OscillogramActivityFilter` для отсеивания \"пустых\" или неактивных осциллограмм.\n",
    "5.  **Генерация коэффициентов нормализации**: На основе активных осциллограмм создаем файл `norm.csv` с помощью `NormalizationCoefficientGenerator`.\n",
    "6.  **Преобразование в CSV**: Конвертируем обработанные (анонимизированные, активные, нормализованные) осциллограммы в формат CSV с помощью `OscillogramToCsvConverter` для дальнейшего анализа или использования в ML.\n",
    "7.  **Специализированный анализ (пример)**: Краткая демонстрация запуска одного из анализаторов, например, `SPEFAnalyzer` или `OvervoltageDetector`.\n",
    "\n",
    "Все пути к файлам и директориям, а также конфигурации, являются примерами и должны быть адаптированы под реальные задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно**: Этот ноутбук использует образцы файлов из директории `tests/sample_data/`. Для демонстрации файлы копируются во временную рабочую директорию (`temp_workflow_notebook_demonstration/...`). Убедитесь, что тестовые данные были сгенерированы запуском скрипта `tests/test_data_setup.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "import csv\n",
    "import zipfile \n",
    "import sys\n",
    "\n",
    "# --- Пути к данным для тестирования ---\n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from core.oscillogram import Oscillogram\n",
    "from filesystem.finder import OscillogramFinder, TYPE_OSC\n",
    "from preprocessing.anonymizer import DataAnonymizer\n",
    "from preprocessing.signal_names import SignalNameManager\n",
    "from analysis.activity_filter import OscillogramActivityFilter, ChannelType\n",
    "from normalization.normalization import NormalizationCoefficientGenerator, OscillogramNormalizer\n",
    "from raw_to_csv.raw_to_csv import OscillogramToCsvConverter \n",
    "# from analysis.spef import SPEFAnalyzer # Uncomment if SPEF demo is fleshed out\n",
    "# from analysis.overvoltage_detector import OvervoltageDetector # Uncomment if OV demo is fleshed out\n",
    "\n",
    "base_sample_data_dir = os.path.join(module_path, \"tests\", \"sample_data\")\n",
    "comtrade_samples_path = os.path.join(base_sample_data_dir, \"comtrade_files\")\n",
    "archive_samples_path = os.path.join(base_sample_data_dir, \"archives\")\n",
    "config_samples_path = os.path.join(base_sample_data_dir, \"config_files\")\n",
    "\n",
    "# --- Основные директории для рабочего процесса в этом ноутбуке ---\n",
    "notebook_base_workflow_dir = \"temp_workflow_notebook_demonstration\"\n",
    "initial_source_dir_wf = os.path.join(notebook_base_workflow_dir, \"00_initial_source\")\n",
    "staging_dir_found_wf = os.path.join(notebook_base_workflow_dir, \"01_staging_found_oscillograms\")\n",
    "# staging_dir_anonymized_wf и staging_dir_active_wf будут созданы позже копированием\n",
    "notebook_output_configs_dir_wf = os.path.join(notebook_base_workflow_dir, \"output_and_configs_workflow\")\n",
    "\n",
    "if os.path.exists(notebook_base_workflow_dir):\n",
    "    shutil.rmtree(notebook_base_workflow_dir)\n",
    "os.makedirs(initial_source_dir_wf)\n",
    "os.makedirs(staging_dir_found_wf) \n",
    "os.makedirs(notebook_output_configs_dir_wf)\n",
    "print(f\"Созданы базовые директории в: {notebook_base_workflow_dir}\")\n",
    "\n",
    "# --- Функция для копирования с проверкой ---\n",
    "def copy_wf_sample(src_full_path, dest_dir):\n",
    "    if os.path.exists(src_full_path):\n",
    "        os.makedirs(dest_dir, exist_ok=True) # Убедимся, что директория существует\n",
    "        shutil.copy(src_full_path, os.path.join(dest_dir, os.path.basename(src_full_path)))\n",
    "        return True\n",
    "    print(f\"ОШИБКА: Исходный файл для workflow не найден: {src_full_path}\")\n",
    "    return False\n",
    "\n",
    "# --- Наполнение initial_source_dir_wf ---\n",
    "all_setup_ok = True\n",
    "# Активная осциллограмма (из данных для ActivityFilter)\n",
    "all_setup_ok &= copy_wf_sample(os.path.join(comtrade_samples_path, \"for_activity_filter\", \"osc_af_active.cfg\"), initial_source_dir_wf)\n",
    "all_setup_ok &= copy_wf_sample(os.path.join(comtrade_samples_path, \"for_activity_filter\", \"osc_af_active.dat\"), initial_source_dir_wf)\n",
    "# \"Пустая\" осциллограмма\n",
    "all_setup_ok &= copy_wf_sample(os.path.join(comtrade_samples_path, \"for_activity_filter\", \"osc_af_empty_stable.cfg\"), initial_source_dir_wf)\n",
    "all_setup_ok &= copy_wf_sample(os.path.join(comtrade_samples_path, \"for_activity_filter\", \"osc_af_empty_stable.dat\"), initial_source_dir_wf)\n",
    "# Осциллограмма в поддиректории\n",
    "workflow_subdir_path = os.path.join(initial_source_dir_wf, \"workflow_subdir\")\n",
    "os.makedirs(workflow_subdir_path, exist_ok=True)\n",
    "all_setup_ok &= copy_wf_sample(os.path.join(comtrade_samples_path, \"valid_cfg_dat_1_subdir\", \"sample_A.cfg\"), workflow_subdir_path)\n",
    "all_setup_ok &= copy_wf_sample(os.path.join(comtrade_samples_path, \"valid_cfg_dat_1_subdir\", \"sample_A.dat\"), workflow_subdir_path)\n",
    "# Архив\n",
    "all_setup_ok &= copy_wf_sample(os.path.join(archive_samples_path, \"archive_A.zip\"), initial_source_dir_wf) # archive_A.zip содержит sample_arc_A.cfg/dat\n",
    "# Текстовый файл\n",
    "with open(os.path.join(initial_source_dir_wf, \"readme.txt\"), \"w\") as f: f.write(\"some info\")\n",
    "\n",
    "# Конфигурационные файлы, которые будут использоваться (копируем их в notebook_output_configs_dir_wf)\n",
    "all_setup_ok &= copy_wf_sample(os.path.join(config_samples_path, \"dict_analog_names_sample.json\"), notebook_output_configs_dir_wf)\n",
    "all_setup_ok &= copy_wf_sample(os.path.join(config_samples_path, \"dict_discrete_names_sample.json\"), notebook_output_configs_dir_wf)\n",
    "all_setup_ok &= copy_wf_sample(os.path.join(config_samples_path, \"activity_filter_config.json\"), notebook_output_configs_dir_wf)\n",
    "\n",
    "if not all_setup_ok: print(\"ВНИМАНИЕ: Не все файлы для демонстрации рабочего процесса были успешно настроены.\")\n",
    "else: print(f\"Содержимое {initial_source_dir_wf} и {notebook_output_configs_dir_wf} подготовлено.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 1: Обнаружение и сбор осциллограмм (`OscillogramFinder`)\n",
    "Копируем только файлы COMTRADE (.cfg/.dat) из `initial_source_dir` (включая архивы) в `staging_dir_found`.\n",
    "Сохраняем структуру директорий и используем хеши для избежания дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder_wf = OscillogramFinder(is_print_message=True, show_progress_bars=True)\n",
    "initial_hashes_path_wf = os.path.join(notebook_output_configs_dir_wf, \"_hash_table_workflow.json\") \n",
    "# Finder будет создавать _hash_table.json в dest_dir (staging_dir_found_wf),\n",
    "# но мы можем указать ему использовать существующий или сохранить копию в notebook_output_configs_dir_wf.\n",
    "# Для этого демо, мы позволим ему создать его в staging_dir_found_wf.\n",
    "# initial_hashes_path_wf здесь будет использован для отображения, если нужно.\n",
    "\n",
    "ft_flags = {type_enum: False for type_enum in TYPE_OSC} \n",
    "ft_flags[TYPE_OSC.COMTRADE_CFG_DAT] = True\n",
    "ft_flags[TYPE_OSC.ARCH_ZIP] = True\n",
    "ft_flags[TYPE_OSC.ARCH_7Z] = True \n",
    "ft_flags[TYPE_OSC.ARCH_RAR] = True \n",
    "\n",
    "copied_count_wf = finder_wf.copy_new_oscillograms(\n",
    "    source_dir=initial_source_dir_wf,\n",
    "    dest_dir=staging_dir_found_wf,\n",
    "    preserve_dir_structure=True,\n",
    "    use_hashes=True,\n",
    "    file_type_flags=ft_flags,\n",
    "    max_archive_depth=1, \n",
    "    show_progress_method=True\n",
    ")\n",
    "print(f\"\\nЭтап 1: Скопировано {copied_count_wf} осциллограмм в {staging_dir_found_wf}\")\n",
    "print(f\"Содержимое {staging_dir_found_wf}:\")\n",
    "for root, dirs, files in os.walk(staging_dir_found_wf):\n",
    "    level = root.replace(staging_dir_found_wf, '').count(os.sep)\n",
    "    indent = ' ' * 4 * (level)\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    sub_indent = ' ' * 4 * (level + 1)\n",
    "    for f_name in files: print(f\"{sub_indent}{f_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 2: Анонимизация (`DataAnonymizer`)\n",
    "Анонимизируем файлы в `staging_dir_found` и сохраняем их в `staging_dir_anonymized`.\n",
    "DataAnonymizer сам переименовывает файлы в хеши и кладет их в ту же директорию, где нашел.\n",
    "Поэтому для чистоты эксперимента, сначала скопируем файлы в `staging_dir_anonymized`, а потом анонимизируем их там."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем директорию для анонимизированных файлов\n",
    "staging_dir_anonymized_wf = os.path.join(notebook_base_workflow_dir, \"02_staging_anonymized\")\n",
    "if os.path.exists(staging_dir_anonymized_wf): shutil.rmtree(staging_dir_anonymized_wf)\n",
    "shutil.copytree(staging_dir_found_wf, staging_dir_anonymized_wf, dirs_exist_ok=True) \n",
    "print(f\"Скопированы файлы из {staging_dir_found_wf} в {staging_dir_anonymized_wf} для анонимизации.\")\n",
    "\n",
    "anonymizer_wf = DataAnonymizer(verbose_logging=True, show_progress_bars=True)\n",
    "anonymizer_wf.anonymize_directory(staging_dir_anonymized_wf) \n",
    "\n",
    "print(f\"\\nЭтап 2: Анонимизация завершена в {staging_dir_anonymized_wf}.\")\n",
    "print(f\"Содержимое {staging_dir_anonymized_wf} (файлы должны быть переименованы в хеши):\")\n",
    "for root, dirs, files in os.walk(staging_dir_anonymized_wf):\n",
    "    level = root.replace(staging_dir_anonymized_wf, '').count(os.sep)\n",
    "    indent = ' ' * 4 * (level)\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    sub_indent = ' ' * 4 * (level + 1)\n",
    "    for f_name in files: print(f\"{sub_indent}{f_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 3: Каталогизация имен сигналов (`SignalNameManager`)\n",
    "Создадим каталог имен сигналов из анонимизированных файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_wf = SignalNameManager(verbose_logging=False, show_progress_bars=True)\n",
    "catalog_path_wf = os.path.join(notebook_output_configs_dir_wf, \"workflow_signal_catalog.csv\")\n",
    "sm_wf.find_signal_names(staging_dir_anonymized_wf, \n",
    "                        output_csv_path=catalog_path_wf, \n",
    "                        verbose_logging_method=True, \n",
    "                        show_progress_method=True)\n",
    "\n",
    "if os.path.exists(catalog_path_wf):\n",
    "    print(\"\\nСодержимое каталога сигналов:\")\n",
    "    try: from IPython.display import display; display(pd.read_csv(catalog_path_wf))\n",
    "    except ImportError: print(pd.read_csv(catalog_path_wf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 4: Фильтрация по активности (`OscillogramActivityFilter`)\n",
    "Отфильтруем \"пустые\" осциллограммы из анонимизированной директории. Результаты (список активных файлов) сохраним в CSV. Затем скопируем только активные файлы в `staging_dir_active_wf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем конфигурацию ActivityFilter из файла (скопированного в setup)\n",
    "activity_filter_config_path_wf = os.path.join(notebook_output_configs_dir_wf, \"activity_filter_config.json\")\n",
    "activity_filter_config_wf = {}\n",
    "if os.path.exists(activity_filter_config_path_wf):\n",
    "    with open(activity_filter_config_path_wf, 'r', encoding='utf-8') as f_cfg_af:\n",
    "        activity_filter_config_wf = json.load(f_cfg_af)\n",
    "else:\n",
    "    print(f\"ОШИБКА: Файл конфигурации {activity_filter_config_path_wf} не найден. Используется дефолтная конфигурация.\")\n",
    "    # Можно задать дефолтную конфигурацию здесь, если нужно\n",
    "    activity_filter_config_wf = {'use_norm_osc': False, 'channels_to_analyze_patterns': ['U_Active', 'I_Stable', 'U_Archived']}\n",
    "    # Дополнить дефолтную конфигурацию необходимыми ключами, если они отсутствуют\n",
    "    if 'raw_signal_analysis' not in activity_filter_config_wf:\n",
    "        activity_filter_config_wf['raw_signal_analysis'] = {\n",
    "            'initial_window_check_periods': 1, 'h1_vs_hx_ratio_threshold_U': 2, \n",
    "            'h1_vs_hx_ratio_threshold_I': 2,'min_initial_h1_amplitude_for_rel_norm': 0.005,\n",
    "            'thresholds_raw_current_relative': {'delta': 0.1, 'std_dev': 0.05},\n",
    "            'thresholds_raw_voltage_relative': {'delta': 0.1, 'std_dev': 0.05}\n",
    "        }\n",
    "    if 'current_channel_id_patterns' not in activity_filter_config_wf: activity_filter_config_wf['current_channel_id_patterns'] = ['i ']\n",
    "    if 'voltage_channel_id_patterns' not in activity_filter_config_wf: activity_filter_config_wf['voltage_channel_id_patterns'] = ['u ']\n",
    "\n",
    "# На данном этапе у нас еще нет файла norm.csv для workflow, поэтому normalizer=None или use_norm_osc=False\n",
    "activity_filter_config_wf['use_norm_osc'] = False \n",
    "activity_filter_wf = OscillogramActivityFilter(config=activity_filter_config_wf, normalizer=None, show_progress_bars=True)\n",
    "\n",
    "active_files_report_path_wf = os.path.join(notebook_output_configs_dir_wf, \"workflow_active_files.csv\")\n",
    "\n",
    "print(f\"\\nФильтрация по активности в {staging_dir_anonymized_wf}...\")\n",
    "activity_filter_wf.filter_directory(staging_dir_anonymized_wf, active_files_report_path_wf, show_progress=True)\n",
    "\n",
    "# Создаем директорию для активных файлов\n",
    "staging_dir_active_wf = os.path.join(notebook_base_workflow_dir, \"03_staging_active_oscillograms\")\n",
    "if os.path.exists(staging_dir_active_wf): shutil.rmtree(staging_dir_active_wf)\n",
    "os.makedirs(staging_dir_active_wf)\n",
    "\n",
    "if os.path.exists(active_files_report_path_wf):\n",
    "    active_files_df = pd.read_csv(active_files_report_path_wf)\n",
    "    if not active_files_df.empty and 'active_files' in active_files_df.columns:\n",
    "        print(f\"\\nКопирование {len(active_files_df)} активных файлов в {staging_dir_active_wf}...\")\n",
    "        for _, row in active_files_df.iterrows():\n",
    "            active_cfg_name = row['active_files'] \n",
    "            for root, _, files in os.walk(staging_dir_anonymized_wf):\n",
    "                if active_cfg_name in files:\n",
    "                    src_cfg_path = os.path.join(root, active_cfg_name)\n",
    "                    src_dat_path = os.path.join(root, active_cfg_name[:-4] + \".dat\")\n",
    "                    \n",
    "                    relative_dir = os.path.relpath(root, staging_dir_anonymized_wf)\n",
    "                    dest_subdir_active = os.path.join(staging_dir_active_wf, relative_dir)\n",
    "                    os.makedirs(dest_subdir_active, exist_ok=True)\n",
    "                    \n",
    "                    dest_cfg_path = os.path.join(dest_subdir_active, active_cfg_name)\n",
    "                    dest_dat_path = os.path.join(dest_subdir_active, active_cfg_name[:-4] + \".dat\")\n",
    "                    \n",
    "                    if os.path.exists(src_cfg_path): shutil.copy2(src_cfg_path, dest_cfg_path)\n",
    "                    if os.path.exists(src_dat_path): shutil.copy2(src_dat_path, dest_dat_path)\n",
    "                    break \n",
    "        print(f\"Содержимое {staging_dir_active_wf} после копирования активных файлов:\")\n",
    "        for root, dirs, files in os.walk(staging_dir_active_wf):\n",
    "            level = root.replace(staging_dir_active_wf, '').count(os.sep)\n",
    "            indent = ' ' * 4 * (level); print(f\"{indent}{os.path.basename(root)}/\")\n",
    "            sub_indent = ' ' * 4 * (level + 1)\n",
    "            for f_name in files: print(f\"{sub_indent}{f_name}\")\n",
    "    else:\n",
    "        print(\"Активных файлов для копирования не найдено.\")\n",
    "else:\n",
    "    print(\"Отчет об активных файлах не создан.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 5: Генерация коэффициентов нормализации (`NormalizationCoefficientGenerator`)\n",
    "Используем активные, анонимизированные осциллограммы из `staging_dir_active_wf` для генерации `norm_coeffs_workflow.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_norm_csv_path = os.path.join(notebook_output_configs_dir_wf, \"norm_coeffs_workflow.csv\") \n",
    "\n",
    "coeff_gen_wf = NormalizationCoefficientGenerator(\n",
    "    osc_path=staging_dir_active_wf, # Директория с осциллограммами для анализа\n",
    "    # prev_norm_csv_path=workflow_norm_csv_path, # Если хотим дописывать в существующий\n",
    "    prev_norm_csv_path=\"\", \n",
    "    bus=1,\n",
    "    is_print_message=False # Управляется через tqdm внутри класса\n",
    ")\n",
    "\n",
    "print(\"\\nЗапуск генерации коэффициентов нормализации...\")\n",
    "coeff_gen_wf.normalization(output_filename=workflow_norm_csv_path) # Указываем путь для сохранения\n",
    "\n",
    "if os.path.exists(workflow_norm_csv_path):\n",
    "    print(f\"\\nФайл коэффициентов '{workflow_norm_csv_path}' успешно создан.\")\n",
    "    try: from IPython.display import display; display(pd.read_csv(workflow_norm_csv_path).head())\n",
    "    except ImportError: print(pd.read_csv(workflow_norm_csv_path).head())\n",
    "else:\n",
    "    print(f\"\\nОшибка: Файл '{workflow_norm_csv_path}' не был создан.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 6: Преобразование в CSV (`OscillogramToCsvConverter`)\n",
    "Конвертируем активные, анонимизированные осциллограммы в CSV, используя сгенерированные коэффициенты нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_analog_names_path = os.path.join(notebook_output_configs_dir_wf, \"dict_analog_names_sample.json\") # Используем скопированный\n",
    "wf_analog_content = { \"bus1\": { \n",
    "    \"U_Active\": [\"U_Active\"], \"I_Stable\": [\"I_Stable\"], \n",
    "    \"U_Active_Sub\": [\"U_Active_Sub\"], \"U_Archived\": [\"U_Archived\"]\n",
    "} }\n",
    "# Перезаписывать стандартный файл не будем, используем тот, что скопирован в notebook_output_configs_dir_wf\n",
    "# with open(wf_analog_names_path, \"w\", encoding=\"utf-8\") as f: json.dump(wf_analog_content, f)\n",
    "wf_discrete_names_path = os.path.join(notebook_output_configs_dir_wf, \"dict_discrete_names_sample.json\") # Используем скопированный\n",
    "wf_discrete_content = { \"bus1\": { \"ML_Event\": [\"ML_Event_Dummy\"]}}\n",
    "# with open(wf_discrete_names_path, \"w\", encoding=\"utf-8\") as f: json.dump(wf_discrete_content, f)\n",
    "\n",
    "if not os.path.exists(workflow_norm_csv_path):\n",
    "    print(f\"Файл {workflow_norm_csv_path} не найден! Пропускаем этап конвертации в CSV.\")\n",
    "else:\n",
    "    normalizer_workflow = OscillogramNormalizer(norm_coef_file_path=workflow_norm_csv_path, is_print_message=False)\n",
    "\n",
    "    converter_wf = OscillogramToCsvConverter(\n",
    "        normalizer=normalizer_workflow,\n",
    "        raw_path=staging_dir_active_wf, \n",
    "        csv_path=notebook_output_configs_dir_wf, \n",
    "        # uses_buses=['1'], # Опционально, если нужно указать конкретные шины\n",
    "        dict_analog_names_path=wf_analog_names_path,\n",
    "        dict_discrete_names_path=wf_discrete_names_path,\n",
    "        is_print_message=False,\n",
    "        show_progress_bars=True\n",
    "    )\n",
    "    converter_wf.number_periods = 1 \n",
    "\n",
    "    final_csv_name = \"final_dataset.csv\"\n",
    "    print(f\"\\nЗапуск финального преобразования в CSV (выход: {final_csv_name})...\")\n",
    "    df_final = converter_wf.create_csv(csv_name=final_csv_name, is_cut_out_area=True, is_simple_csv=False)\n",
    "\n",
    "    if df_final is not None and not df_final.empty:\n",
    "        print(f\"\\nПервые строки итогового CSV ({final_csv_name}):\")\n",
    "        try: from IPython.display import display; display(df_final.head())\n",
    "        except ImportError: print(df_final.head())\n",
    "        print(f\"Колонки: {df_final.columns.tolist()}\")\n",
    "    else:\n",
    "        print(f\"Итоговый CSV не был создан или пуст.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 7: Специализированный анализ (Пример: `SPEFAnalyzer`)\n",
    "Это опциональный шаг. Можно запустить любой из анализаторов на полученных данных.\n",
    "Для `SPEFAnalyzer` потребовалась бы более специфичная настройка `norm.csv` и конфигурации самого анализатора.\n",
    "Здесь просто обозначим возможность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nПример вызова SPEFAnalyzer (закомментирован, требует своей конфигурации):\")\n",
    "# spef_config_wf = { \n",
    "# 'VALID_NOMINAL_VOLTAGES': {6000.0/np.sqrt(3)}, # Пример\n",
    "# 'SPEF_THRESHOLD_U0': 0.05, 'SPEF_THRESHOLD_Un': 0.03, \n",
    "# 'SPEF_MIN_DURATION_PERIODS': 1, \n",
    "# 'SIMILAR_AMPLITUDES_FILTER_ENABLED': True, \n",
    "# 'SIMILAR_AMPLITUDES_MAX_RELATIVE_DIFFERENCE': 0.15, \n",
    "# 'verbose': True, 'norm_yes_phrase': 'YES' \n",
    "# }\n",
    "# if os.path.exists(workflow_norm_csv_path):\n",
    "#     norm_coeffs_df_wf = pd.read_csv(workflow_norm_csv_path)\n",
    "#     spef_analyzer_wf = SPEFAnalyzer(\n",
    "#         config=spef_config_wf,\n",
    "#         normalizer=normalizer_workflow, # Уже есть\n",
    "#         bus_splitter=converter_wf,    # Уже есть (OscillogramToCsvConverter)\n",
    "#         norm_coef_df=norm_coeffs_df_wf\n",
    "#     )\n",
    "#     spef_report_path_wf = os.path.join(notebook_output_configs_dir_wf, \"workflow_spef_report.csv\")\n",
    "#     spef_error_log_wf = os.path.join(notebook_output_configs_dir_wf, \"workflow_spef_errors.log\")\n",
    "#     spef_analyzer_wf.analyze_directory(staging_dir_active_wf, spef_report_path_wf, spef_error_log_wf)\n",
    "#     if os.path.exists(spef_report_path_wf):\n",
    "#         print(\"Отчет SPEF:\")\n",
    "#         try: from IPython.display import display; display(pd.read_csv(spef_report_path_wf))\n",
    "#         except ImportError: print(pd.read_csv(spef_report_path_wf))\n",
    "# else:\n",
    "#     print(\"Файл norm.csv не найден, анализ SPEF пропущен.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 8: Очистка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка временной директории\n",
    "try:\n",
    "    if os.path.exists(notebook_base_workflow_dir):\n",
    "        shutil.rmtree(notebook_base_workflow_dir)\n",
    "        print(f\"\\nВременная директория {notebook_base_workflow_dir} удалена.\")\n",
    "    else:\n",
    "        print(f\"\\nВременная директория {notebook_base_workflow_dir} не найдена для удаления.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при удалении временной директории {notebook_base_workflow_dir}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
