# План Фазы 1: Подготовка инфраструктуры и базы для исследований

> **Цель:** Создать надежный фундамент для проведения сравнительных экспериментов (KAN vs CNN vs MLP) и расширения задач (сегментация, автоэнкодеры).
> **Срок:** 2-3 недели

---

## 1. Рефакторинг модуля `osc_tools/ml`

Текущая структура `osc_tools/ml` ориентирована на эксперименты. Нужно привести её к модульному виду, поддерживающему разные архитектуры.

### 1.1. Новая структура директорий
Создать следующую структуру:
```
osc_tools/ml/
├── __init__.py              # Экспорт основных классов ✅ Выполнено
├── models/                  # Архитектуры моделей
│   ├── __init__.py          # ✅ Выполнено
│   ├── base.py              # Абстрактный базовый класс (BaseModel) ✅ Выполнено
│   ├── mlp.py               # Реализации MLP (PDR_MLP, SimpleMLP) ✅ Выполнено
│   ├── cnn.py               # Реализации 1D CNN (ResNet1D, SimpleCNN) ✅ Выполнено
│   ├── experimental.py      # Старые/экспериментальные модели ✅ Выполнено
│   ├── kan.py               # Реализации KAN (SimpleKAN, ConvKAN) ✅ Выполнено
│   ├── autoencoders.py      # AE, VAE, KAN-AE ✅ Выполнено (Placeholder)
│   └── unet.py              # U-Net для сегментации ✅ Выполнено (Placeholder)
├── layers/                  # Строительные блоки
│   ├── __init__.py          # ✅ Выполнено
│   ├── kan_layers.py        # Обертки над pykan/efficient-kan ✅ Выполнено
│   ├── complex_ops.py       # Комплексные операции (существующие) ✅ Выполнено
│   └── blocks.py            # ResBlock, PDRBlock ✅ Выполнено
└── utils.py                 # Утилиты (подсчет параметров, инициализация) ✅ Выполнено
```

### 1.2. Реализация базовых классов
- **`BaseModel`**: Должен иметь методы `forward`, `predict`, `save`, `load`. ✅ Выполнено
- **`PDRBlock`**: Вынести существующий блок из `models.py` в `layers/blocks.py`. ✅ Выполнено

---

## 2. Реализация Baseline моделей (Сравнение)

Для того чтобы показать эффективность KAN, нам нужны сильные, но понятные противники.

### 2.1. MLP (Multi-Layer Perceptron)
- **`SimpleMLP`**: Классическая полносвязная сеть с BatchNormalization и Dropout. ✅ Выполнено
- **Параметры**: Настраиваемое количество слоев и нейронов.

### 2.2. 1D CNN (Convolutional Neural Network)
- **`SimpleCNN`**: 2-3 сверточных слоя + MaxPool + FC слои. ✅ Выполнено
- **`ResNet1D`**: Более глубокая сеть с residual connections (стандарт для временных рядов). ✅ Выполнено
- **Вход**: Сырые данные (raw waveform) или спектрограммы.

---

## 3. Подготовка данных (Data Pipeline)

Нужно научить наши `Dataset` и `DataLoader` работать с новыми задачами.

### 3.1. Унификация входов
- **Raw**: `(Batch, Channels, Time)` — для CNN/U-Net. ✅ Выполнено (поддерживается в Dataset)
- **Features**: `(Batch, Features)` — для MLP/KAN (PDR, классификация по признакам). ✅ Выполнено (поддерживается в Dataset)
- **Phasors**: `(Batch, Channels)` complex — для CVKAN. ✅ Выполнено (поддерживается в Dataset)

### 3.2. Расширение `OscillogramDataset`
Добавить поддержку режимов:
- **`mode='classification'`**: Возвращает `(data, label)`. Label — тип аварии (int). ✅ Выполнено
- **`mode='segmentation'`**: Возвращает `(data, mask)`. Mask — размерности `Time`, содержит класс для каждого отсчета. ✅ Выполнено
- **`mode='reconstruction'`**: Возвращает `(data, data)`. Для автоэнкодеров. ✅ Выполнено

---

## 4. Инфраструктура экспериментов

Чтобы не запутаться в сотнях запусков, нужна система конфигурации и логирования.

### 4.1. Конфигурация (Hydra или dataclasses)
Создать структуру конфигов для экспериментов:
```python
@dataclass
class ExperimentConfig:
    model_type: str      # 'kan', 'cnn', 'mlp'
    task: str            # 'pdr', 'classification', 'segmentation'
    dataset_path: str
    model_params: dict
    training_params: dict
```
✅ Выполнено (реализовано через dataclasses в `osc_tools/ml/config.py`)

### 4.2. Runner экспериментов
Скрипт `run_experiment.py`, который:
1. Читает конфиг.
2. Инициализирует модель и датасеты.
3. Запускает обучение.
4. Логирует метрики (TensorBoard/WandB/CSV).
5. Сохраняет лучшие веса и отчет.
✅ Выполнено (реализован `ExperimentRunner` в `osc_tools/ml/runner.py`)

---

## 5. Интеграция KAN библиотек

### 5.1. Выбор бэкенда
- Исследовать `efficient-kan` (быстрее) и `pykan` (оригинал). ✅ Выполнено (использована реализация `efficient-kan` из `osc_tools/ml/kan_conv`)
- Создать обертку `KANLayer`, которая позволяет переключать реализацию через конфиг. ✅ Выполнено (`KANLinear` и `KANConv1d` в `osc_tools/ml/layers/kan_layers.py`)

### 5.2. Тестирование
- Написать простой unit-тест: `KANLayer` должен обучаться на функции $y = sin(x) + x^2$. ✅ Выполнено (тесты в `tests/unit/test_ml_kan.py`)

---

## Итог Фазы 1
Все задачи выполнены. Инфраструктура готова к проведению экспериментов.
- Рефакторинг ML модуля завершен.
- Базовые модели (MLP, CNN, ResNet) реализованы.
- Датасеты унифицированы.
- KAN слои интегрированы.
- Runner экспериментов создан.

---

## План действий по дням (Примерный)

### Неделя 1: Рефакторинг и Baseline
- **День 1-2**: Создание новой структуры папок, перенос существующего кода PDR в `models/mlp.py` и `layers/blocks.py`.
- **День 3**: Реализация `SimpleCNN` и `ResNet1D` в `models/cnn.py`.
- **День 4-5**: Обновление `OscillogramDataset` для поддержки разных режимов (raw/features).

### Неделя 2: KAN и Инфраструктура
- **День 1-2**: Интеграция `efficient-kan`, создание `models/kan.py`.
- **День 3**: Написание `run_experiment.py` и системы конфигов.
- **День 4-5**: Тестовые запуски всех трех типов моделей (MLP, CNN, KAN) на небольшом наборе данных PDR.

### Неделя 3: Отладка и подготовка к масштабным тестам
- Отладка пайплайнов.
- Проверка сохранения/загрузки моделей.
- Подготовка скриптов для визуализации сравнения.
